python /weka/oe-adapt-default/tengx/main/open-instruct/mason.py \
  --cluster ai2/jupiter-cirrascale-2  \
  --image tengx/open_instruct_main_google2  --pure_docker_mode \
  --workspace  ai2/tulu-thinker \
  --priority high \
  --preemptible \
  --gpus 8 \
  --budget ai2/oe-adapt \
  --num_nodes 1 \
  --max_retries 0 \
   -- python scripts/data/rlvr/filtering_vllm.py \
  --model /weka/oe-adapt-default/jacobm/checkpoints/olmo2-7B-sft/rl-sft/olmo2-7B-FINAL-lc-OT3-full-regen-wc-oasst-ccn-pif-qif-wgwj-syn2-aya-tgpt-ncode-scode \
  --dataset TTTXXX01/MathSub-30K  \
  --split train \
  --chat_template olmo_thinker \
  --offset 10000 \
  --size 11000 \
  --tensor_parallel_size 8 \
    --output-file /weka/oe-adapt-default/tengx/Data/filter_MathSub/MathSub_test_10000_11000.jsonl \
  --number_samples 8